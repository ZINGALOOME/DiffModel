{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPB7h2KR4I7Zwjo8XZCy/DA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ZINGALOOME/DiffModel/blob/main/ImageGenerationPersonalProject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "m6paazYEowso",
        "outputId": "089de6e8-02a4-404f-8335-7e3287786e80"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' This google colab notebook is going to be dedicated towards an image generation project'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "\"\"\" This google colab notebook is going to be dedicated towards an image generation project\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A diffusion model works by taking an input x0 and gradually adding gaussian noise to it for T steps. This is called the forward process.\n",
        "\n",
        "After this a neural network is trained to recover an image from said noise by performing a reversion of the noise process. By being able to model this reverse process we are able to generate new data"
      ],
      "metadata": {
        "id": "cT4SGTZOcejF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1: Forward diffusion\n",
        "\n",
        "Diffusion models can be seen as latent variable models. Latent means we are reffering to a hidden feature space which makes them look similar to variational autoencoders.\n",
        "\n",
        "They are formulated by using a Markov Chain of T steps. In this context the markov chain just means that each step depends on the previous step.\n",
        "\n",
        "Given a data point x0 sampled from the real data distribution q(x) (x ~  q(x)).\n",
        "\n",
        "At each step of the Markov Chain we add Gaussian noise with variance with variance Beta_t to x_t-1, producing a new latent variable x_t with data distribution q(x_t | x_t-1)\n",
        "\n",
        "q(x_t | x_t-1) = N(x_t; mu_t = sqrt(1-Beta_t)x_t-1, sigma_t = Beta_t)\n",
        "\n",
        "q(x|x_t-1) is still a normal distribution defined by the mean \"mu\" and the variance \"sigma\" where mu_t = sqrt(1 - Beta_t)x_t-1 and sigma_t = Beta_t * I * sigma will always be a diagonal matrix of variances (here Beta_t)\n",
        "\n",
        "Thus we can go in a closed form from the input data x_0 to x_T in a tractable way. Mathematically, this is the posterior probability and is defined as:\n",
        "\n",
        "q(x_1:T | x_0) = cumulative_prod(from t=1 to T) q(x_t| x_t-1)\n",
        "\n",
        "The symbol: in q(x_1:T) states that we apply q repeatedly from timestep 1 to T. It's also called the trajectory.\n",
        "\n",
        "In order to avoid having to avoid having to repeatedly apply q for T steps we can perform the reparameterization trick\n",
        "\n",
        "# Step 2: Tractable closed-form sampling at any timestep\n",
        "\n",
        "Assuming we define alpha_t = 1 - beta_t, cumulative_alpha_t = cumulative_prod(from s = 0 to t)alpha_s where e_0, ...., e_t-2, e_t-1 ~ N(O, I), one can use the reparameterization trick in a recursive manner to obtain x_t = sqrt(cum_prod(a_t))x_0 + sqrt(1-cum_prod(a_t)e_0)\n",
        "\n",
        "x_t ~ q(x_t|x_0) = N(x_t; sqrt(cum_prod(a_t))x_0, (1-cum_prod(a_t)I)\n",
        "\n",
        "Since Beta_t is a hyperparameter, we can precompute a_t and cum_prod(a_t) for all timesteps t and get x_t in one go.\n",
        "\n",
        "# Step 3: Variance Schedule\n",
        "\n",
        "The variance parameter Beta_t can be fixed to a constant or chosen asa schedule over T timesteps. The schedule can be linear, quadratic, cosine, etc. The original DDPM authors used a linear schedule increasing from Beta_1 = 10^-4 to B_T = 0.02.\n",
        "\n",
        "# Step 4: Reverse diffusion\n",
        "\n",
        "As T approaches infinity, the latent x_T is nearly an isotropic Gaussian distribution. Which means if we manage to learn the distribution q(x_t-1| x_t), we can sample x_T from N(0,I), run the reverse process and acquire a sample from q(x_0) generatinga novel data point from the orignal data distribution, but how do we model the reverse distribution process?\n",
        "\n",
        "# Step 5: Approximating the reverse process with a neural network\n",
        "\n",
        "In practical terms, we don't know q(x_t-1|x_t) it's intractable since statistical estimates of q(x_t-1|x_t) require computations involving the data distribution.\n",
        "\n",
        "Instead we approximate q(x_t-1| x_t) with a parameterized model p_0 (e.g. a neural network). Since q(x_t-1|x_t) will also be Gaussian, for small enough Beta_t, wecan choose p_0 to be Gaussian and just parameterize the mean and variance:"
      ],
      "metadata": {
        "id": "SacGKQZOdUh4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "class Diffusion:\n",
        "\n",
        "  def __init__(self , timesteps = 1000 ,img_shape = (3, 128, 128) ,device = \"gpu\", ):\n",
        "\n",
        "    self.timesteps = timesteps\n",
        "    self.img_shape = img_shape\n",
        "    self.device = device\n",
        "    self.initialise()\n",
        "\n",
        "  def initialise(self):\n",
        "    self.beta = self.get_betas()\n",
        "    self.alpha = 1 - self.beta\n",
        "\n",
        "\n",
        "    self.sqrt_beta = torch.sqrt(self.beta)\n",
        "    self.sqrt_alpha = torch.sqrt(self.alpha)\n",
        "\n",
        "    self.cumprod_alpha = torch.cumprod(self.alpha, dim=0)\n",
        "    self.cumprod_beta = torch.cumprod(self.beta, dim=0)\n",
        "\n",
        "\n",
        "    self.sqrt_alpha_cumulative = torch.sqrt(self.cumprod_alpha)\n",
        "    self.sqrt_beta_cumulative = torch.sqrt(self.cumprod_beta)\n",
        "\n",
        "    self.one_over_sqrt_alpha = 1/torch.sqrt(self.alpha)\n",
        "    self.sqrt_one_minus_alpha_cumulative = torch.sqrt(1 - self.cumprod_alpha)\n",
        "\n",
        "\n",
        "  def get_betas(self):\n",
        "\n",
        "    scale = 1000/self.timesteps\n",
        "    beta_start = scale * 1e-4\n",
        "    beta_end = scale * 0.02\n",
        "\n",
        "    return torch.linspace(\n",
        "        beta_start,\n",
        "        beta_end,\n",
        "        self.timesteps,\n",
        "        dtype=torch.float32,\n",
        "        device=self.device,\n",
        "    )\n",
        "\n",
        "def forward_diffusion(sd: Diffusion, x0: torch.Tensor, timesteps: torch.Tensor):\n",
        "\n",
        "  eps = torch.randn_like(x0)\n",
        "  mean = get(sd.sqrt_alpha_cumulative, t=timesteps) * x0\n",
        "  std_dev = get(sd.sqrt_one_minus_alpha_cumulative, t=timesteps)\n",
        "  sample = mean * std_dev * eps\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0OeZ1CcIrDbe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}